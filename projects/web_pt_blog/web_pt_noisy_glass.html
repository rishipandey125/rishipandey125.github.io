<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">

    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet">

    <title>The Beauty of Accessible Light Simulation</title>

    <style>
      html {
        background-color: #ffffff;
      }

      body {
        background-color: #ffffff;
        font-family: 'Roboto Mono', monospace;
      }

      .error {
        padding: 5%;
        line-height: 2;
        top: 50%;
        position: relative;
        transform: translateY(-50%);
      }

      .intro {
        display: flex;
        justify-content: center;
        align-items: center;
      }
    </style>
</head>

<body>
    <!-- top title -->
    <div class="container-fluid mt-5">
        <div class="row justify-content-md-center align-items-center">
            <div class="col col-lg-4">
            <!-- space at top! -->
            </div>
            <div class="col col-lg-4 hidden-lg-up" align="center" >
            </div>
        </div>
        </div>
    
        <!-- Intro -->
        <div class="container mb-3">
        <div class ="row intro">
            <div class="col-md-10" align="left">
                <h1>The Beauty of Accessible Light Simulation </h1>
                <p>&nbsp;</p> 
                <p class="">published 10/16/22</p>
                <p class="">by <a href="https://twitter.com/wookiepandey25" target="_blank">Rishi Pandey üå∫</a></p>
                <p>&nbsp;</p> 
            </div>
        </div>

        <div class="row intro">
            <div class="col-md-10" align="left">
                <h4>Light Simulation is Beautfiul</h4>
                <p class="">I‚Äôve always been fascinated by <a href="https://en.wikipedia.org/wiki/Path_tracing" target="_blank">path tracing</a> and physically based lighting models. I think that stems from my early admiration of films by <a href="http://www.ilm.com" target="_blank">ILM</a> and <a href="https://graphics.pixar.com/library/" target="_blank">Pixar</a>. Only when I was older did I start diving into learning about the years of R&D that went into production rendering.</p>
                <p class="">Light scattering in a scene is something that you can feel. You know what is right and wrong, there is a ground truth that we are all familiar with.</p>
                <p class="">That ground truth is rooted in complex mathematics that simulate the transport of light to create imagery. It feels quite magical to witness how computation can be used to create something so physically authentic. That is what I find truly beautiful about it.</p>
                <p class="">However, production rendering tools are expensive ($$$ hardware and computation) and therefore often inaccessible for independent artists.</p>
            </div>
        </div>
        <p>&nbsp;</p> 
        <div class="row intro">
            <div class="col-md-10" align="left">
                <h4>The Artistic Acessibility of the Internet</h4>
                <p class="">A lot of my artistic and technical exploration lately has been focused on mobile and the web. The accessibility of the internet as a medium has let me rapidly design, prototype, and publish my work using simple tools, no ‚Äúhigh-end‚Äù equipment necessary.</p>
                <p class="">Web/mobile is becoming an increasingly interactive space for computational artists. I feel like path tracing tools would perfectly empower web-artists to explore what interactions, art, and algorithms may look like when exactly simulated.</p>
                <p class="">This idea of combining the perfectly calculated beauty of path tracing along with the rapid prototyping culture of web exploration inspired my first exploration into web based light simulation.</p>
            </div>
        </div>
        <p>&nbsp;</p> 
        <div class="row intro">
            <div class="col-md-5" align="left">
                <h4>Orbs</h4>
                <p class="">is a generative art piece designed and engineered in a fragment shader via GLSL.</p>
                <p class="">The piece you see is unique to you!</p>
                <p class="">Refreshing/Reloading this blog will generate a new piece.</p>
            </div>
            <div class="col-md-5" align="center">
                <div id="container"></div>
            </div>
        </div>
        <p>&nbsp;</p> 
        <div class="row intro">
            <div class="col-md-10" align="left">
                <p class="">The shader was engineered based on Peter Shirley‚Äôs <a href="https://raytracing.github.io/" target="_blank">Ray Tracing in One Weekend</a> series, focusing on integrating a global illumination path tracer, parallelized per pixel on the GPU.</p>
                <p class="">The piece leverages features such as diffuse and dielectric materials, global illumination, texture mapping, <a href="https://iquilezles.org/articles/fbm/" target="_blank">Fractional Brownian Motion</a>, and progressive rendering to create a scene with a noisy glass ball.</p>
                <p class="">The value to sample the Fractial Brownian Motion and glass color are the generative elements of the piece and are what allowed me to express the computational simulation as a piece of art.</p>
                <p class="">Progressive rendering was by far one of my favorite features to integrate! </p>
                <p class="">It allows for the accumulation of noisy (low quality) renders to then be averaged to make a high quality image. A new noisy render is calculated every frame, which means that every frame the quality of the piece improves.</p>
                <p class="">You can tell when you refresh the page that the piece starts noisy, and quickly improves in quality from there.</p>
                <p class="">I find it really cool that you can accumulate many low quality simulations that are very easy to compute to average and create a high quality result.</p>
            </div>
        </div>
        <p>&nbsp;</p> 
        <div class="row intro">
            <div class="col-md-10" align="left">
                <h4>What's Next?!</h4>
                <p class="">This piece was just a simple first step in exploring light simulation for interactive experiences and art on the web! I am really excited to continue to advance the renderer and elevate it from a shader based art piece to a bespoke light simulation web design tool.</p>
                <p class="">As mentioned earlier, path tracing can get computationally expensive quickly. To create nimble path tracing powered interactive design tools acceleration structures and optimization features are vital.</p>
                <p class="">Progressive rendering is a great example of a feature that enables a path tracer to be used as a tool or an experience.</p>
                <p class="">It allows you to iterate in the design process on your scene at an interactive framerate using low-quality render settings, but still output a high-quality result via accumulation.</p>
                <p class="">There are a lot of amazing artists and engineers exploring internet tools for physically based rendering. We are all working hard to empower internet artists/designers with tools to explore algorithmic and artistic expression with light simulation.</p>
            </div>
        </div>
        <div class="row intro">
            <div class="col-md-10" align="left">
                <a href="http://www.rishi-pandey.com/" target="_blank">home</a></p>
            </div>
        </div>
        <p>&nbsp;</p> 
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.js"></script>

    <script id="vertexShader" type="x-shader/x-vertex">
        void main()	{
            gl_Position = vec4( position, 1.0 );
        }
    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
        #define M_PI 3.1415926535897932384626433832795

        precision highp float;

        //global uniforms 
        uniform float u_Time; //overall time 
        uniform vec2 u_Resolution; //vec2(screen_width,screen_height)

        //progressive rendering uniforms
        uniform sampler2D u_Frame; //prev render for progressive rendering
        uniform float u_numFrames; //count of progressive frames

        //camera uniforms
        uniform float u_vFov;
        uniform vec3 u_camOrigin;
        uniform vec3 u_camLookAt;
        uniform float u_Aperture; 

        //scene geometry
        const int MAX_GEOMETRY = 5;
        uniform float u_sceneGeometryEnabled[MAX_GEOMETRY];
        uniform float u_sceneGeometryMaterial[MAX_GEOMETRY];
        uniform vec4 u_sceneGeometryProperties[2*MAX_GEOMETRY];


        uniform float u_NoiseScale;


        //random functions using gold noise 
        float seed = 0.0;

        uint base_hash(uvec2 p) {
            p = 1103515245U*((p >> 1U)^(p.yx));
            uint h32 = 1103515245U*((p.x)^(p.y>>3U));
            return h32^(h32 >> 16);
        }

        float hash1(float seed) {
            uint n = base_hash(floatBitsToUint(vec2(seed+=.1,seed+=.1)));
            return float(n)*(1.0/float(0xffffffffU));
        }
        //
        // Noise functions by Inigo Quilez:
        // https://www.shadertoy.com/view/4sfGzS
        //

        float hash(vec3 p) {
            p  = fract( p*0.3183099+.1 );
            p *= 17.0;
            return 2. * fract( p.x*p.y*p.z*(p.x+p.y+p.z) ) - 1.;
        }

        float noise(const in vec3 x ) {
            vec3 p = floor(x);
            vec3 f = fract(x);
            f = f*f*(3.0-2.0*f);
            
            return mix(mix(mix( hash(p+vec3(0,0,0)), 
                                hash(p+vec3(1,0,0)),f.x),
                        mix( hash(p+vec3(0,1,0)), 
                                hash(p+vec3(1,1,0)),f.x),f.y),
                    mix(mix( hash(p+vec3(0,0,1)), 
                                hash(p+vec3(1,0,1)),f.x),
                        mix( hash(p+vec3(0,1,1)), 
                                hash(p+vec3(1,1,1)),f.x),f.y),f.z);
        }

        float fbm(const in vec3 p, const in int octaves) {
            float accum = 0.;
            vec3 temp_p = p;
            float weight = 1.;
            
            for (int i=0; i<octaves; i++) {
                accum += weight * noise(temp_p);
                weight *= .5;
                temp_p *= 2.;
            }
            return abs(accum);
        }

        float random (vec2 st) {
            return fract(sin(dot(st.xy,
                                 vec2(12.9898,78.233)))*
                43758.5453123);
        }

        vec2 random2(float seed) {
            return vec2(
              random(vec2(seed-1.23, (seed+3.1)* 3.2)),
              random(vec2(seed+12.678, seed - 5.8324))
              );
        }
          
        vec3 random3(float seed){
            return vec3(
                random(vec2(seed-0.678, seed-0.123)),
                random(vec2(seed-0.3, seed+0.56)),
                random(vec2(seed+0.1234, seed-0.523))
                );
        }


        vec3 random_in_unit_sphere(float seed) {
            vec3 h = random3(seed) * vec3(2.,6.28318530718,1.)-vec3(1,0,0);
            float phi = h.y;
            float r = pow(h.z, 1./3.);
            return r * vec3(sqrt(1.-h.x*h.x)*vec2(sin(phi),cos(phi)),h.x);
        }
         
        vec3 random_unit_vector(float seed) {
            return normalize(random_in_unit_sphere(seed));
        }

        vec2 random_in_unit_disk(float seed) {
            vec2 h = random2(seed) * vec2(1.,6.28318530718);
            float phi = h.y;
            float r = sqrt(h.x);
            return r * vec2(sin(phi),cos(phi));
        }

        struct ray {
            vec3 origin;
            vec3 direction;
        };

        struct material {
            int type; //material type
            vec3 albedo; //material base color
            float v; // value for material
        };

        struct camera {
            vec3 origin, lower_left_corner, horizontal, vertical; 
            float focal_length, lens_radius;
            vec3 u,v;
        };

        struct hit_record { 
            vec3 point;
            vec3 normal;
            float t;
            material mat;
        };
        
        vec3 reflect(vec3 v, vec3 n) {
            return v - (2.0*dot(v,n)*n);
        }

        float schlick(float cosine, float ior) {
            float r0 = (1.-ior)/(1.+ior);
            r0 = r0*r0;
            return r0 + (1.-r0)*pow((1.-cosine),5.);
        }

        bool modified_refract(const in vec3 v, const in vec3 n, const in float ni_over_nt, out vec3 refracted) {
            float dt = dot(v, n);
            float discriminant = 1. - ni_over_nt*ni_over_nt*(1.-dt*dt);
            if (discriminant > 0.) {
                refracted = ni_over_nt*(v - n*dt) - n*sqrt(discriminant);
                return true;
            } else { 
                return false;
            }
        }
        
        vec3 sample_noise(vec3 p) {
            float s = u_NoiseScale;
            return vec3(.5*(1. + sin(s*p.z + 5.*fbm((s*.5)*p, 7))));
        }

        bool material_scatter(const in ray r, const in hit_record rec, out vec3 attenuation, out ray r_scatter) {
            if (rec.mat.type == 0) { //lambertian
                vec3 rd = normalize(rec.normal + random_unit_vector(seed));
                r_scatter = ray(rec.point,rd);
                attenuation = rec.mat.albedo;
                return true;
            } else if (rec.mat.type == 1) { //metal
                vec3 rd = reflect(r.direction, rec.normal);
                r_scatter = ray(rec.point, normalize(rd + rec.mat.v*random_in_unit_sphere(seed)));
                attenuation = rec.mat.albedo;
                return true;
            } else if (rec.mat.type == 2) { //dielctric
                vec3 outward_normal, refracted, 
                reflected = reflect(r.direction, rec.normal);
                float ni_over_nt, reflect_prob, cosine;
                attenuation = mix(rec.mat.albedo,vec3(1.0),sample_noise(rec.point)); // here is where we want to change the glass color
                if (dot(r.direction, rec.normal) > 0.) {
                    outward_normal = -rec.normal;
                    ni_over_nt = rec.mat.v;
                    cosine = dot(r.direction, rec.normal);
                    cosine = sqrt(1. - rec.mat.v*rec.mat.v*(1.-cosine*cosine));
                } else {
                    outward_normal = rec.normal;
                    ni_over_nt = 1. / rec.mat.v;
                    cosine = -dot(r.direction, rec.normal);
                }
                
                if (modified_refract(r.direction, outward_normal, ni_over_nt, refracted)) {
                    reflect_prob = schlick(cosine, rec.mat.v);
                } else {
                    reflect_prob = 1.;
                }
                
                if (hash1(seed) < reflect_prob) {
                    r_scatter = ray(rec.point, reflected);
                } else {
                    r_scatter = ray(rec.point, refracted);
                }
                //calculate the uv cord on the glass sphere
                return true;
            } 
            return false;
        }

        vec3 material_emit(hit_record rec) {
            if (rec.mat.type == 3) { //emitter
                return rec.mat.albedo*rec.mat.v;
            }
            return vec3(0.0);
        }

        struct hittable { // this is just a sphere right now 
            vec3 center; 
            float radius; 
        };

        ray get_camera_ray(camera c, vec2 uv, float seed) {
            vec2 radius = c.lens_radius * random_in_unit_disk(seed);
            vec3 offset = (c.u * radius.x)+ (c.v * radius.y);
            return ray(c.origin + offset,c.lower_left_corner + (uv.x*c.horizontal) + (uv.y*c.vertical) - c.origin - offset);
        }

        vec3 get_point_on_ray(ray r, float t) {
            return r.origin + (t*r.direction);
        }
        
        bool hittable_hit (hittable h, ray r, float t_min, float t_max, inout hit_record rec) {
            vec3 oc = r.origin - h.center;
            float a = dot(r.direction,r.direction);
            float half_b = dot(oc,r.direction);
            float c = dot(oc,oc) - h.radius*h.radius;
            float discriminant = (half_b*half_b) - (a*c);
            if (discriminant < 0.0) {
                return false;
            }
            float root =  (-half_b - sqrt(discriminant))/a;
            //determine which root is in bounds
            if (root < t_min || t_max < root) {
                root = ((-half_b) + sqrt(discriminant))/a;
                if (root < t_min || t_max < root) {
                    return false;
                }
            }
            rec.t = root; 
            rec.point = get_point_on_ray(r,root);
            rec.normal = (rec.point - h.center)/h.radius;
            // add the uv cords of the hit 

            return true;
        }
        
        //sphere spatial vec4(x,y,z,rad)
        //sphere material id vec2(exists, id)
        //sphere material info vec4(color,value)

        bool world_hit(ray r, float t_min, float t_max, out hit_record rec) {
            rec.t = t_max;
            bool hit = false;
            
            for (int i = 0; i < MAX_GEOMETRY; i++) {  
                if (u_sceneGeometryEnabled[i] > 0.0) {
                    vec4 spatialInformation = u_sceneGeometryProperties[i*2];
                    hittable object = hittable(spatialInformation.rgb,spatialInformation.a);
                    if (hittable_hit(object,r,t_min,rec.t,rec)) {
                        hit = true;
                        int materialID = int(u_sceneGeometryMaterial[i]);
                        vec4 materialProperties = u_sceneGeometryProperties[(i*2)+1];
                        rec.mat = material(materialID,materialProperties.rgb,materialProperties.a);
                    }
                }
            } 
            
            return hit;
        }


        vec3 bg_color(ray r) {
            vec3 unit_direction = normalize(r.direction);
            float t = 0.5 * (unit_direction.y + 1.0);
            vec3 light_blue = vec3(0.5,0.7,1.0);
            vec3 white = vec3(1.0);
            vec3 bg = mix(white,light_blue,t);
            return bg;
        }

        vec3 color(ray r) {
            hit_record rec;

            vec3 color = vec3(0.0);
            vec3 emitted = vec3(0.0);

            //loop max is max recursion
            for (int i = 0; i < 10; i++) {
                bool hit = world_hit(r,0.001,1e5,rec);
                if (hit) {
                    ray scattered;
                    vec3 attenuation;
                    vec3 emit = material_emit(rec);
                    emitted += i == 0 ? emit : color * emit;

                    //scatter the next ray based on the material stored in the hit record
                    if (material_scatter(r,rec,attenuation,scattered)) {
                        color = i == 0 ? attenuation : color * attenuation;
                        r = scattered;
                    } else {
                        return emitted; //should do nothing I think
                    }
                } else {
                    return emitted;
                }
            }
            
            return emitted;
        }

        vec3 gamma_correction(float scale, vec3 c) {
            vec3 gamma;
            //gamma correction
            gamma.r = sqrt(scale*c.r);
            gamma.g = sqrt(scale*c.g);
            gamma.b = sqrt(scale*c.b);
            return gamma;
        }

        vec3 unit_vector(vec3 vector)  {
            return vector/(sqrt(dot(vector,vector)));
        }

        void main( void ) {
            //image
            float aspect_ratio = u_Resolution.x/u_Resolution.y;

            //camera
            camera c;

            float theta = radians(u_vFov);

            float h = tan(theta/2.0);
            
            float viewport_height = 2.0 * h;
            float viewport_width = viewport_height * aspect_ratio;

            vec3 look_from = u_camOrigin;
            vec3 look_at = u_camLookAt;
            vec3 vup = vec3(0.0,1.0,0.0);

            float focus_dist = length(look_from-look_at);
            
            vec3 w = normalize(look_from - look_at);

            c.u = normalize(cross(vup,w));

            c.v = cross(w,c.u);

            c.focal_length = 1.0;
            c.origin = look_from;
            // how far we should traverse the viewport horizontally and vertically to cast rays

            c.horizontal = focus_dist * vec3(viewport_width) * c.u;
            c.vertical = focus_dist * vec3(viewport_height) * c.v;

            //viewport lower left corner in 3d space
            c.lower_left_corner = c.origin - (c.horizontal/2.0) - (c.vertical/2.0) - (focus_dist*w);

            c.lens_radius = u_Aperture / 2.0;

            vec2 uv = gl_FragCoord.xy / u_Resolution.xy; //calc quad uv (0-1) down to up and left to right

            //seed 
            seed = random(uv.xy * mod(u_Time,100.0));
            
            vec3 pixel_color = vec3(0.0);
            
            ray r = get_camera_ray(c,uv+random2(seed)*0.001,seed);
            pixel_color += color(r);

            pixel_color = gamma_correction(1.0,pixel_color);

            float i = 1.0 / (u_numFrames + 1.0);
            vec4 prevTex = texture2D(u_Frame,uv);
            vec4 final = vec4(pixel_color,1.0);
            gl_FragColor = mix(prevTex,final,i);
        }
    </script>
    <script>
        //global variables
        var container; // store the div 
        var camera, scene, renderer; 
        var uniforms, material, mesh; 

        var ping, pong; 

        var numFrames = 0; //initialize renderer frame count 
        
        var maxSceneGeometry = 3;
        var sceneGeometryEnabled = [] //float 0 is not enabled and 1 is enabled
        var sceneGeometryMaterial = [] //material id 0-3 
        var sceneGeometryProperties = [] //vec4(x,y,z,rad) in first row and vec4(vec3(rgb),v) in second row

        var noiseScale; 
        var col = []

        var w;
        var h;
        var renderTargetParams;

        function randomRange(min, max) {
            return min + (Math.random()*(max-min));
        }

        function mix(start,end,val) {
            return start + (val * (end-start));
        }

        function populateScene() {
            //provides a dome
            sceneGeometryEnabled.push(1) //visiblity
            sceneGeometryMaterial.push(3) //materialid
            sceneGeometryProperties.push(new THREE.Vector4(0,0,0,100.0)) //position and radius
            sceneGeometryProperties.push(new THREE.Vector4(1,1,1, 1.0 )) //albedo and material value

            //setup ground sphere
            sceneGeometryEnabled.push(1) //visiblity
            sceneGeometryMaterial.push(0) //materialid
            sceneGeometryProperties.push(new THREE.Vector4(0,-100.5,1,100.0)) //position and radius
            sceneGeometryProperties.push(new THREE.Vector4(1, 1, 1, 0.0 )) //albedo and material value

            col = [randomRange(0,1),randomRange(0,1),randomRange(0,1)]

            sceneGeometryEnabled.push(1) //visiblity
            sceneGeometryMaterial.push(2) //materialid
            sceneGeometryProperties.push(new THREE.Vector4(0,0.5,0,1.0)) //position and radius
            sceneGeometryProperties.push(new THREE.Vector4(col[0], col[1], col[2], 1.5 )) //albedo and material value
            
            sceneGeometryEnabled.push(1) //visiblity
            sceneGeometryMaterial.push(2) //materialid
            sceneGeometryProperties.push(new THREE.Vector4(0,0.5,0,-0.95)) //position and radius
            sceneGeometryProperties.push(new THREE.Vector4(col[0], col[1], col[2], 1.5 )) //albedo and material value
            
            // //extra sphere
            sceneGeometryEnabled.push(1) //visiblity
            sceneGeometryMaterial.push(0) //materialid
            sceneGeometryProperties.push(new THREE.Vector4(0,10,0,1.0)) //position and radius
            sceneGeometryProperties.push(new THREE.Vector4(randomRange(1,1),randomRange(1,1),randomRange(1,1), 10.0 )) //albedo and material value

        }

        init(); //onStart

        var startTime = Date.now();

        animate(); //onUpdate

        //onStart
        function init() {
            //bug only works for screen at 50% right now
            container = document.getElementById('container');

            camera = new THREE.Camera(); //create a camera to setup screenspace material
            camera.position.z = 0;
            scene = new THREE.Scene();

           renderTargetParams = { //render target settings for ping-ponging textures
                minFilter: THREE.LinearFilter,
                magFilter: THREE.NearestFilter,
                format: THREE.RGBAFormat,
                type: THREE.FloatType
            };
    
            let aspectRatio = 1; //canvas aspect ratio
            let canvasHeight = 500; //height of canvas
            let canvasWidth = canvasHeight*aspectRatio; //width based on aspect ratio
            
            //enforce conditions for mobile friendly canvas
            if (window.innerWidth < canvasWidth) {
                //make canvas mobile friendly
                canvasWidth = 0.8*window.innerWidth;
                canvasHeight = canvasWidth * (1/aspectRatio);
            }
            w = canvasWidth; //width and height of the user screen
            h = canvasHeight;
            
            //initialize ping pong textures
            ping = new THREE.WebGLRenderTarget(w, h, renderTargetParams );
            pong = new THREE.WebGLRenderTarget(w, h, renderTargetParams );

            populateScene(); //populate scene with geometry 
            noiseScale = randomRange(1,20);
            //create shader uniforms
            uniforms = {
                u_Frame: { type : 't', value : pong.texture },
                u_numFrames: { type: "f", value: numFrames },
                u_Time: { type: "f", value: 1.0 },
                u_NoiseScale: { type: "f", value: noiseScale},
                u_Resolution: { type: "v2", value: new THREE.Vector2() },
                u_vFov: { type : "f", value: 75.0},
                u_Aperture: { type: "f", value: 0.0},
                u_camOrigin: { type: "v3", value: new THREE.Vector3(0,3,3)},
                u_camLookAt: { type: "v3", value: new THREE.Vector3(0,0.3,0)},
                u_sceneGeometryEnabled: { type: "fv", value: sceneGeometryEnabled},
                u_sceneGeometryMaterial: { type: "fv", value: sceneGeometryMaterial},
                u_sceneGeometryProperties: { type: "v4v", value: sceneGeometryProperties}
            };

            //create screenspace material with vert and frag shaders
            material = new THREE.ShaderMaterial({
                uniforms: uniforms,
                vertexShader: document.getElementById('vertexShader').textContent,
                fragmentShader: document.getElementById('fragmentShader').textContent
            });

            //create the quad and add it to the screen
            mesh = new THREE.Mesh(new THREE.PlaneGeometry(2, 2), material);
            scene.add(mesh);

            //create the renderer 
            renderer = new THREE.WebGLRenderer({ preserveDrawingBuffer: true });

            //update resolution uniform
            uniforms.u_Resolution.value.x = w;
            uniforms.u_Resolution.value.y = h;
            
            //set renderer settings and add it to the div
            renderer.setSize(w, h);
            // renderer.setPixelRatio( window.devicePixelRatio ); //to use antialiasing on mobile
            container.appendChild(renderer.domElement);

        }

        //onUpdate 
        function animate() {
            requestAnimationFrame(animate); //tick 
            render(); //render! 
        }

        //CPU rendering function called every frame
        function render() {
            //Draw ping to buffer 
            renderer.setRenderTarget(ping);
            renderer.render(scene, camera);

            renderer.setRenderTarget(null);
            renderer.clear();
                
            //Swap ping and pong
            let temp = pong;
            pong = ping;
            ping = temp;

            //update uniforms for GPU 
            mesh.material.map = ping; //render to ping
            uniforms.u_Frame.value=pong; //use pong as the frame texture

            uniforms.u_numFrames.value = numFrames; //update the num frames 
            
            uniforms.u_NoiseScale.value = noiseScale;

            //calculate time and update time uniform
            var elapsedMilliseconds = Date.now() - startTime;
            var elapsedSeconds = elapsedMilliseconds / 1000.;
            uniforms.u_Time.value = elapsedSeconds;

            //render the scene
            renderer.render(scene, camera);

            //increment the number of frames
            numFrames += 1;
        }
    </script>
</body>

</html>